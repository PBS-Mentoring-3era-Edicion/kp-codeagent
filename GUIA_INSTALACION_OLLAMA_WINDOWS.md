# ü™ü Gu√≠a Oficial de Instalaci√≥n de Ollama en Windows

## ‚ÑπÔ∏è Informaci√≥n Oficial

Basado en la documentaci√≥n oficial de Ollama: https://github.com/ollama/ollama/blob/main/docs/windows.md

---

## üìã Requisitos del Sistema

- **Windows 10 versi√≥n 22H2 o superior** (Home o Pro)
- **8 GB de RAM m√≠nimo** (para modelos 7B como phi)
- **Para aceleraci√≥n GPU**:
  - NVIDIA: Drivers 452.39+
  - AMD: Radeon drivers actualizados
- **Espacio en disco**: 2-10 GB por modelo

---

## üöÄ Instalaci√≥n en Windows (Nativo)

### Paso 1: Descargar el Instalador

1. Ve a: https://ollama.com/download
2. Descarga `OllamaSetup.exe`
3. Ejecuta el instalador

**Nota importante**:
- ‚úÖ Ollama se instala **nativamente en Windows**
- ‚ùå **NO necesitas WSL** para usar Ollama
- ‚úÖ Se instala en tu cuenta de usuario (no requiere permisos de admin)
- ‚úÖ Se actualiza autom√°ticamente

### Paso 2: Verificar la Instalaci√≥n

Despu√©s de instalar, abre **PowerShell** o **Command Prompt** (Windows nativo, NO WSL):

```powershell
# Verificar que Ollama est√° instalado
ollama --version
```

**Resultado esperado**:
```
ollama version is 0.X.X
```

### Paso 3: Verificar que el Servicio Est√° Corriendo

```powershell
# En Windows, el servicio deber√≠a iniciar autom√°ticamente
# Verifica con:
curl http://localhost:11434/api/version
```

**Resultado esperado**:
```json
{"version":"0.X.X"}
```

**Si NO funciona**:
- Busca "Ollama" en el men√∫ de inicio y ejec√∫talo
- O abre PowerShell y ejecuta: `ollama serve`

---

## üì¶ Instalar Modelos

### Descargar phi (Modelo Peque√±o y R√°pido)

```powershell
# En PowerShell/CMD de Windows (no WSL)
ollama pull phi
```

**Proceso**:
```
pulling manifest
pulling 1e67dff39209... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.6 GB
pulling 2931454c2cd4... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  122 B
pulling c71d239df917... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   10 KB
pulling 31df454bc2c5... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  485 B
verifying sha256 digest
writing manifest
success
```

‚è±Ô∏è **Tiempo estimado**: 3-10 minutos (depende de tu conexi√≥n a internet)

### Listar Modelos Instalados

```powershell
ollama list
```

**Resultado esperado**:
```
NAME            ID              SIZE      MODIFIED
phi:latest      e2fd6321a5fe    1.6 GB    X minutes ago
```

---

## üß™ Probar que Funciona

### Prueba B√°sica

```powershell
ollama run phi "Say hello in one word"
```

**Primera vez (carga el modelo)**:
- ‚è±Ô∏è Tarda 10-20 segundos la primera vez
- üíæ Carga el modelo en memoria

**Resultado esperado**:
```
Hello
```

**Siguientes veces**:
- ‚ö° Responde en 2-5 segundos
- Modelo ya est√° en memoria

### Prueba Interactiva

```powershell
ollama run phi
```

Esto abre un chat interactivo:
```
>>> Hello!
Hi! How can I help you today?

>>> /bye
```

---

## üîç Verificaci√≥n Completa Paso a Paso

### 1. Ollama est√° instalado
```powershell
ollama --version
```
‚úÖ Debe mostrar: `ollama version is 0.X.X`

### 2. Servicio est√° corriendo
```powershell
curl http://localhost:11434/api/version
```
‚úÖ Debe mostrar: `{"version":"0.X.X"}`

### 3. Modelo descargado
```powershell
ollama list
```
‚úÖ Debe mostrar phi en la lista

### 4. Modelo funciona
```powershell
ollama run phi "test"
```
‚úÖ Debe responder en menos de 20 segundos

---

## üêõ Problemas Comunes y Soluciones

### ‚ùå "command not found: ollama"

**Causa**: Ollama no est√° instalado o no est√° en el PATH

**Soluci√≥n**:
1. Reinstala desde https://ollama.com/download
2. Cierra y abre PowerShell de nuevo
3. Si persiste, reinicia Windows

### ‚ùå "Connection refused" al hacer curl

**Causa**: El servicio de Ollama no est√° corriendo

**Soluci√≥n**:
```powershell
# Opci√≥n 1: Busca "Ollama" en el men√∫ inicio y ejec√∫talo

# Opci√≥n 2: Desde PowerShell
ollama serve
```

Deja esa ventana abierta y abre otra PowerShell para ejecutar comandos.

### ‚ùå Responde muy lento (>60 segundos)

**Causa**: Falta de RAM, CPU lenta, o antivirus bloqueando

**Soluci√≥n**:
1. Cierra otros programas (navegadores, etc.)
2. Prueba con modelo a√∫n m√°s peque√±o:
   ```powershell
   ollama pull tinyllama
   ollama run tinyllama "test"
   ```
3. Desactiva temporalmente el antivirus (solo para probar)
4. Revisa logs en: `%LOCALAPPDATA%\Ollama\logs`

### ‚ùå "Error loading model"

**Causa**: Descarga incompleta o corrupta

**Soluci√≥n**:
```powershell
# Volver a descargar el modelo
ollama pull phi
```

---

## üîß Ubicaciones Importantes

### Logs
```
%LOCALAPPDATA%\Ollama\logs
```

En PowerShell:
```powershell
explorer $env:LOCALAPPDATA\Ollama\logs
```

### Modelos descargados
```
%USERPROFILE%\.ollama\models
```

En PowerShell:
```powershell
explorer $env:USERPROFILE\.ollama\models
```

---

## üéØ Usando Ollama desde WSL

Si tienes Ollama instalado en **Windows** y quieres usarlo desde **WSL**:

### Paso 1: Obt√©n la IP de Windows

En **PowerShell** (Windows):
```powershell
ipconfig
```

Busca la IP de "vEthernet (WSL)" o similar, ejemplo: `172.X.X.X`

### Paso 2: Conecta desde WSL

En **WSL**:
```bash
# Usa la IP de Windows en lugar de localhost
curl http://172.X.X.X:11434/api/version
```

### Paso 3: Configura kp-codeagent en WSL

Edita el c√≥digo para usar la IP de Windows en lugar de `localhost`:

```python
# En kp_codeagent/ollama_client.py
def __init__(self, base_url: str = "http://172.X.X.X:11434", ...):
```

**O mejor**: Usa variable de entorno:
```bash
export OLLAMA_HOST="http://172.X.X.X:11434"
```

---

## ‚úÖ Checklist de Instalaci√≥n Exitosa

Marca cada paso cuando lo completes:

- [ ] OllamaSetup.exe descargado e instalado
- [ ] `ollama --version` funciona en PowerShell
- [ ] `curl http://localhost:11434/api/version` responde
- [ ] `ollama pull phi` completado exitosamente
- [ ] `ollama list` muestra phi
- [ ] `ollama run phi "test"` responde en menos de 30s
- [ ] (Opcional) Conexi√≥n desde WSL funciona

---

## üìä Tiempos Esperados (Windows Nativo)

| Operaci√≥n | Primera Vez | Subsecuente |
|-----------|-------------|-------------|
| Cargar modelo phi | 10-20s | Instant√°neo |
| Respuesta simple | 3-8s | 2-5s |
| Respuesta compleja | 10-30s | 5-15s |

**Nota**: Estos son tiempos en Windows nativo. WSL puede ser 2-5x m√°s lento.

---

## üÜò Si Nada Funciona

### Opci√≥n 1: Reinstalaci√≥n Limpia

```powershell
# 1. Desinstalar Ollama
# Ve a: Configuraci√≥n > Aplicaciones > Ollama > Desinstalar

# 2. Eliminar datos residuales
Remove-Item -Recurse -Force $env:LOCALAPPDATA\Ollama
Remove-Item -Recurse -Force $env:USERPROFILE\.ollama

# 3. Reinicia Windows

# 4. Reinstala desde ollama.com/download
```

### Opci√≥n 2: Reportar el Problema

1. Revisa los logs:
   ```powershell
   notepad $env:LOCALAPPDATA\Ollama\logs\server.log
   ```

2. Reporta en: https://github.com/ollama/ollama/issues

3. Incluye:
   - Versi√≥n de Windows
   - Versi√≥n de Ollama
   - Contenido de los logs
   - Qu√© comando falla

---

## üìö Recursos Oficiales

- **P√°gina oficial**: https://ollama.com
- **Documentaci√≥n**: https://github.com/ollama/ollama
- **Windows docs**: https://github.com/ollama/ollama/blob/main/docs/windows.md
- **Modelos disponibles**: https://ollama.com/library
- **Issues**: https://github.com/ollama/ollama/issues

---

## üí° Pr√≥ximos Pasos

Una vez que Ollama funcione correctamente:

1. **Probar con kp-codeagent**:
   ```powershell
   cd kp-codeagent
   kp-codeagent check
   kp-codeagent --model phi run "create hello.py"
   ```

2. **Descargar m√°s modelos**:
   ```powershell
   ollama pull codellama    # Mejor para c√≥digo
   ollama pull llama3       # Modelo general potente
   ```

3. **Explorar la API**:
   ```powershell
   curl http://localhost:11434/api/tags
   ```

---

**√öltima actualizaci√≥n**: 2025-10-13
**Basado en**: Ollama v0.12.3 Windows documentation
