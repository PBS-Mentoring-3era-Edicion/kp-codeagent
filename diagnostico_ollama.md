# üîç Diagn√≥stico de Ollama - Gu√≠a Paso a Paso

## Paso 1: Verificar que Ollama est√© instalado y corriendo

```bash
# Ver si el proceso est√° activo
ps aux | grep ollama | grep -v grep

# Ver versi√≥n de Ollama
ollama --version

# Ver estado del servicio
curl http://localhost:11434/api/version
```

**‚úÖ Esperado:** Deber√≠as ver el proceso corriendo y una versi√≥n como `{"version":"0.x.x"}`

---

## Paso 2: Ver qu√© modelos tienes disponibles

```bash
# Listar modelos instalados
ollama list

# O usando la API
curl http://localhost:11434/api/tags
```

**‚úÖ Esperado:** Deber√≠as ver `codellama:7b` y `phi:latest` en la lista

---

## Paso 3: Prueba simple con el CLI de Ollama

```bash
# Prueba interactiva con phi (modelo peque√±o y r√°pido)
ollama run phi:latest "Di hola en una palabra"
```

**‚è±Ô∏è Tiempo esperado:** 3-15 segundos
**‚ùå Si tarda m√°s de 30 segundos:** Hay un problema de recursos

---

## Paso 4: Prueba con la API directamente (sin streaming)

```bash
# Prueba simple sin streaming
time curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi:latest",
    "prompt": "Say hello",
    "stream": false
  }'
```

**‚è±Ô∏è Tiempo esperado:** 5-20 segundos
**‚úÖ Esperado:** Deber√≠as recibir un JSON con la respuesta

---

## Paso 5: Prueba con streaming (como usa kp-codeagent)

```bash
# Con streaming para ver respuesta en tiempo real
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi:latest",
    "prompt": "Count to 3",
    "stream": true
  }'
```

**‚úÖ Esperado:** Deber√≠as ver m√∫ltiples l√≠neas JSON apareciendo progresivamente

---

## Paso 6: Revisar logs de Ollama

```bash
# Ver logs si Ollama corre como servicio
sudo journalctl -u ollama -f

# O si lo iniciaste manualmente, verifica la terminal donde corre
```

**üîç Busca:** Mensajes de error, warnings sobre memoria, o "loading model"

---

## Paso 7: Verificar uso de recursos

```bash
# Ver uso de RAM y CPU mientras Ollama trabaja
top -p $(pgrep ollama)

# O m√°s detallado
htop -p $(pgrep ollama)

# Ver memoria disponible
free -h
```

**‚ö†Ô∏è Problema com√∫n:**
- `phi:latest` necesita ~2-3 GB de RAM
- `codellama:7b` necesita ~4-6 GB de RAM
- Si tienes menos RAM libre, el sistema usar√° swap (muy lento)

---

## Paso 8: Probar descargar modelo m√°s peque√±o

```bash
# Tiny model para testing (solo ~600MB)
ollama pull tinyllama

# Probar con √©l
ollama run tinyllama "Hello"
```

**‚è±Ô∏è Si tinyllama responde r√°pido:** El problema es falta de RAM para modelos grandes

---

## Paso 9: Reiniciar Ollama limpiamente

```bash
# Detener Ollama
sudo systemctl stop ollama
# O si corre manualmente:
pkill ollama

# Esperar 5 segundos
sleep 5

# Iniciar de nuevo
sudo systemctl start ollama
# O manualmente:
ollama serve

# Esperar 10 segundos a que inicie
sleep 10

# Probar de nuevo
ollama run phi:latest "test"
```

---

## Paso 10: Script autom√°tico de diagn√≥stico

Guarda este script como `test_ollama_detallado.sh`:

```bash
#!/bin/bash

echo "=================================="
echo "üîç DIAGN√ìSTICO COMPLETO DE OLLAMA"
echo "=================================="
echo ""

# Test 1
echo "1Ô∏è‚É£ Verificando proceso Ollama..."
if pgrep -x ollama > /dev/null; then
    echo "   ‚úÖ Ollama est√° corriendo (PID: $(pgrep ollama))"
else
    echo "   ‚ùå Ollama NO est√° corriendo"
    exit 1
fi
echo ""

# Test 2
echo "2Ô∏è‚É£ Verificando API..."
if curl -s http://localhost:11434/api/version > /dev/null; then
    VERSION=$(curl -s http://localhost:11434/api/version | grep -o '"version":"[^"]*"')
    echo "   ‚úÖ API responde: $VERSION"
else
    echo "   ‚ùå API no responde"
    exit 1
fi
echo ""

# Test 3
echo "3Ô∏è‚É£ Listando modelos..."
ollama list
echo ""

# Test 4
echo "4Ô∏è‚É£ Verificando memoria disponible..."
FREE_MEM=$(free -g | awk '/^Mem:/{print $7}')
echo "   RAM libre: ${FREE_MEM}GB"
if [ "$FREE_MEM" -lt 2 ]; then
    echo "   ‚ö†Ô∏è  ADVERTENCIA: Poca memoria libre (necesitas 2-4GB)"
fi
echo ""

# Test 5
echo "5Ô∏è‚É£ Probando generaci√≥n simple (timeout 30s)..."
echo "   Prompt: 'Say hi'"
START=$(date +%s)
timeout 30 ollama run phi:latest "Say hi" > /tmp/ollama_test.txt 2>&1
EXIT_CODE=$?
END=$(date +%s)
DURATION=$((END - START))

if [ $EXIT_CODE -eq 0 ]; then
    echo "   ‚úÖ Respuesta recibida en ${DURATION}s"
    echo "   üìù Respuesta: $(cat /tmp/ollama_test.txt)"
elif [ $EXIT_CODE -eq 124 ]; then
    echo "   ‚è±Ô∏è  TIMEOUT despu√©s de 30s"
    echo "   ‚ùå El modelo est√° demasiado lento"
else
    echo "   ‚ùå Error (code: $EXIT_CODE)"
fi
echo ""

# Test 6
echo "6Ô∏è‚É£ Probando API con timeout..."
START=$(date +%s)
timeout 30 curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "phi:latest", "prompt": "Hi", "stream": false}' \
  > /tmp/ollama_api_test.txt 2>&1
EXIT_CODE=$?
END=$(date +%s)
DURATION=$((END - START))

if [ $EXIT_CODE -eq 0 ]; then
    echo "   ‚úÖ API respondi√≥ en ${DURATION}s"
    RESPONSE=$(cat /tmp/ollama_api_test.txt | grep -o '"response":"[^"]*"' | head -1)
    echo "   üìù Respuesta: $RESPONSE"
elif [ $EXIT_CODE -eq 124 ]; then
    echo "   ‚è±Ô∏è  TIMEOUT despu√©s de 30s"
    echo "   ‚ùå API est√° demasiado lenta"
else
    echo "   ‚ùå Error en API (code: $EXIT_CODE)"
fi
echo ""

# Resumen
echo "=================================="
echo "üìä RESUMEN"
echo "=================================="
if [ $EXIT_CODE -eq 0 ] && [ $DURATION -lt 15 ]; then
    echo "‚úÖ TODO BIEN - Ollama funciona correctamente"
    echo "   El problema puede estar en kp-codeagent"
elif [ $EXIT_CODE -eq 124 ] || [ $DURATION -gt 20 ]; then
    echo "‚ö†Ô∏è  RENDIMIENTO BAJO"
    echo "   Causas posibles:"
    echo "   - Poca RAM disponible"
    echo "   - CPU lenta"
    echo "   - Modelo muy grande para tu hardware"
    echo ""
    echo "   üí° Soluciones:"
    echo "   - Cierra otros programas"
    echo "   - Usa 'tinyllama' en lugar de phi"
    echo "   - Aumenta RAM del sistema"
else
    echo "‚ùå HAY ERRORES - Revisa los logs arriba"
fi
echo "=================================="

# Cleanup
rm -f /tmp/ollama_test.txt /tmp/ollama_api_test.txt
```

**Para ejecutar:**
```bash
chmod +x test_ollama_detallado.sh
./test_ollama_detallado.sh
```

---

## üîß Soluciones Comunes

### Problema: "Timeout despu√©s de 30s"
**Causa:** Falta de RAM o CPU lenta
**Soluci√≥n:**
1. Cierra navegadores y otros programas
2. Reinicia Ollama: `sudo systemctl restart ollama`
3. Prueba modelo m√°s peque√±o: `ollama pull tinyllama`

### Problema: "Model not found"
**Soluci√≥n:**
```bash
ollama pull phi:latest
# Espera a que termine (puede tardar varios minutos)
ollama list  # Verifica que aparezca
```

### Problema: "Connection refused"
**Causa:** Ollama no est√° corriendo
**Soluci√≥n:**
```bash
# Si est√° instalado como servicio
sudo systemctl start ollama

# Si no, in√≠cialo manualmente en otra terminal
ollama serve
```

### Problema: Uso excesivo de memoria
**Soluci√≥n:**
```bash
# Descargar modelo m√°s peque√±o
ollama pull tinyllama

# Usar en kp-codeagent:
kp-codeagent --model tinyllama run "tu tarea"
```

---

## üìä Tabla de Requisitos por Modelo

| Modelo | Tama√±o | RAM Necesaria | Velocidad | Calidad C√≥digo |
|--------|--------|---------------|-----------|----------------|
| tinyllama | 600MB | 1-2 GB | ‚ö°‚ö°‚ö° R√°pido | ‚≠ê‚≠ê B√°sica |
| phi:latest | 1.6GB | 2-3 GB | ‚ö°‚ö° Medio | ‚≠ê‚≠ê‚≠ê Buena |
| codellama:7b | 3.8GB | 4-6 GB | ‚ö° Lento | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| codellama:13b | 7.4GB | 8-12 GB | üêå Muy lento | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Profesional |

---

## ‚úÖ Checklist Final

- [ ] Ollama est√° corriendo
- [ ] API responde en menos de 5 segundos
- [ ] Modelo responde en menos de 30 segundos
- [ ] Tienes al menos 3GB de RAM libre
- [ ] No hay errores en los logs

Si todos est√°n ‚úÖ, entonces kp-codeagent deber√≠a funcionar.
Si alguno falla ‚ùå, ese es tu problema.

---

## üÜò Si Nada Funciona

**Opci√≥n 1: Usar modo demo**
```bash
python3 demo_sin_ia.py  # Ya lo creamos antes
```

**Opci√≥n 2: Documentar el problema**
Para tu portafolio, puedes documentar:
- El problema encontrado
- Los pasos de diagn√≥stico
- Las soluciones intentadas
- Alternativas implementadas (modo demo)

Esto demuestra **habilidades de debugging** y **resoluci√≥n de problemas reales**.
