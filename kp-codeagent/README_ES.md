# ü§ñ KP Code Agent

**Tu Asistente de C√≥digo con IA para Estudiantes**

[English](README.md) | **Espa√±ol**

KP Code Agent es un asistente de programaci√≥n basado en terminal que ayuda a estudiantes a completar tareas de programaci√≥n, aprender mejores pr√°cticas y mejorar sus habilidades - ¬°todo desde la l√≠nea de comandos!

## ‚ö° NUEVO: Backend en la Nube Ultra-R√°pido (Groq) - **RECOMENDADO para WSL**

**Usuarios de WSL**: Si Ollama es lento (>30s), usa **Groq** en su lugar - ¬°es **20x m√°s r√°pido** y **100% GRATIS**!

```bash
# 1. Instala soporte para Groq
pip install groq

# 2. Obt√©n API key GRATIS en https://console.groq.com/keys

# 3. Configura
export GROQ_API_KEY="gsk_tu_key_aqui"

# 4. √ösalo (0.7-2 segundos vs 30-90s con Ollama!)
kp-codeagent --backend groq --lang es run "crea funci√≥n fibonacci"
```

**¬øPor qu√© Groq?**
- ‚ö° **20x m√°s r√°pido** que Ollama en WSL (0.7s vs 47s)
- üÜì **100% GRATIS** (30 requests/min, 14,400/d√≠a)
- üíæ **0 uso de RAM** (corre en la nube)
- üéØ **Mejor calidad de c√≥digo** (modelo Llama 3.3 70B)
- ‚úÖ **Funciona perfectamente en WSL**

üìñ **Gu√≠a completa**: Ver `GUIA_GROQ.md`

---

## ‚ú® Caracter√≠sticas

- üöÄ **S√∫per R√°pido** - 0.7-2s con Groq, sin internet despu√©s con Ollama
- üéì **Enfoque Educativo** - Explica el c√≥digo y ense√±a mejores pr√°cticas
- üîí **Privado y Seguro** - Opci√≥n local con Ollama o nube con Groq
- üí¨ **Interactivo** - Confirma cambios antes de modificar archivos
- üé® **Interfaz de Terminal Hermosa** - Resaltado de sintaxis y salida formateada
- üîÑ **Operaciones de Archivo Seguras** - Respaldos autom√°ticos antes de modificaciones
- üåç **Biling√ºe** - Soporte completo en Espa√±ol e Ingl√©s

## üìã Requisitos

- **Sistema Operativo**: Windows 10/11, macOS, o Linux (incluyendo WSL)
- **Python**: 3.10 o superior
- **Backend**: Elige uno:
  - **Groq** (recomendado para WSL): 0 MB RAM, requiere internet
  - **Ollama** (privado): 4-6GB RAM, sin internet

## üöÄ Inicio R√°pido

### Instalaci√≥n - Elige tu Backend

#### ‚ö° Opci√≥n 1: Groq (Recomendado - R√°pido y F√°cil)

**Mejor para**: WSL, sistemas con poca RAM, configuraci√≥n r√°pida

```bash
# 1. Descarga el repositorio
git clone https://github.com/kp-codeagent/kp-codeagent.git
cd kp-codeagent/kp-codeagent

# 2. Instala dependencias
pip install -r requirements.txt

# 3. Instala KP Code Agent
pip install -e .

# 4. Obt√©n tu API key GRATIS de https://console.groq.com/keys

# 5. Configura
export GROQ_API_KEY="gsk_tu_key_aqui"

# 6. ¬°Listo! Pru√©balo:
kp-codeagent --backend groq --lang es run "crea una funci√≥n hello world"
```

**Tiempo de instalaci√≥n**: ~2 minutos
**Primera respuesta**: 0.7-2 segundos ‚ö°

---

#### üîí Opci√≥n 2: Ollama (Local y Privado)

**Mejor para**: Usuarios enfocados en privacidad, sin internet despu√©s de la instalaci√≥n

```bash
# 1. Descarga el repositorio
git clone https://github.com/kp-codeagent/kp-codeagent.git
cd kp-codeagent

# 2. Ejecuta el instalador
# Windows:
installer\install.bat

# Linux/macOS/WSL:
chmod +x installer/install.sh
./installer/install.sh

# 3. O instalaci√≥n manual:
pip install -r requirements.txt
# Instala Ollama desde https://ollama.ai/download
ollama pull codellama:7b
pip install -e .
```

**Tiempo de instalaci√≥n**: ~5-10 minutos
**Primera respuesta**: 10-60 segundos (m√°s r√°pido despu√©s de la primera carga)

### Primer Uso

#### ‚ö° Con Groq (Recomendado)

1. **Configura tu API key**:
   ```bash
   export GROQ_API_KEY="gsk_tu_key_aqui"

   # Hacerla permanente (opcional):
   echo 'export GROQ_API_KEY="gsk_tu_key"' >> ~/.bashrc
   source ~/.bashrc
   ```

2. **Prueba que funciona**:
   ```bash
   python3 test_groq.py
   ```

   Esperado: ‚úÖ Respuesta en ~0.7 segundos

3. **Ejecuta tu primera tarea**:
   ```bash
   kp-codeagent --backend groq --lang es run "crea una funci√≥n Python para calcular n√∫meros fibonacci"
   ```

4. **Revisa y confirma** los cambios cuando se te solicite

**Rendimiento**:
- ‚ö° Primera respuesta: 0.7-2 segundos
- üÜì Completamente GRATIS (30 req/min, 14,400/d√≠a)
- üíæ 0 uso de RAM en tu m√°quina

---

#### üîí Con Ollama (Alternativa)

##### Para Usuarios de Windows (PowerShell):

1. **Verifica que Ollama est√© instalado y ejecut√°ndose**:
   ```powershell
   ollama --version
   ollama list
   ```

2. **Descarga un modelo** (si no lo hiciste a√∫n):
   ```powershell
   ollama pull codellama:7b
   ```

3. **Ejecuta kp-codeagent**:
   ```powershell
   kp-codeagent check
   kp-codeagent --lang es run "crea una funci√≥n Python para calcular n√∫meros fibonacci"
   ```

##### Para Usuarios de Linux/macOS/WSL:

1. **Verifica si todo est√° listo**:
   ```bash
   kp-codeagent check
   ```

2. **Ejecuta tu primera tarea**:
   ```bash
   kp-codeagent --lang es run "crea una funci√≥n Python para calcular n√∫meros fibonacci"
   ```

**Rendimiento**:
- ‚è±Ô∏è Primera ejecuci√≥n puede tardar 20-60 segundos mientras el modelo carga en memoria
- ü™ü Usuarios de Windows: Ejecuta Ollama **nativamente en Windows**, no en WSL para mejor rendimiento
- üìñ Ver `GUIA_INSTALACION_OLLAMA_WINDOWS.md` para instalaci√≥n detallada en Windows

---

üí° **Consejo**: Si Ollama es lento en WSL, cambia a Groq para obtener ¬°un rendimiento 20x m√°s r√°pido!

## üìñ Uso

### Comando B√°sico

```bash
# Con Groq (recomendado - s√∫per r√°pido)
kp-codeagent --backend groq --lang es run "tu descripci√≥n de tarea aqu√≠"

# Con Ollama (local)
kp-codeagent --lang es run "tu descripci√≥n de tarea aqu√≠"
```

### Ejemplos

**Crear c√≥digo nuevo con Groq**:
```bash
kp-codeagent --backend groq --lang es run "crea una funci√≥n Python que valide direcciones de correo electr√≥nico"
```

**Modificar c√≥digo existente**:
```bash
kp-codeagent --backend groq --lang es run "agrega manejo de errores a la funci√≥n de login en auth.py"
```

**Corregir errores**:
```bash
kp-codeagent --backend groq --lang es run "corrige el error de puntero nulo en main.java"
```

**Agregar funcionalidades**:
```bash
kp-codeagent --backend groq --lang es run "agrega un bot√≥n de modo oscuro a la p√°gina de configuraci√≥n"
```

**Refactorizar c√≥digo**:
```bash
kp-codeagent --backend groq --lang es run "refactoriza el c√≥digo de conexi√≥n a base de datos para usar connection pooling"
```

### Opciones Avanzadas

```bash
# üåü RECOMENDADO: Usar backend Groq (r√°pido, nube, GRATIS)
kp-codeagent --backend groq --lang es run "tu tarea"

# Usar diferentes modelos de Groq
kp-codeagent --backend groq --model llama-3.3-70b-versatile --lang es run "tarea"      # Default
kp-codeagent --backend groq --model llama-3.1-8b-instant --lang es run "tarea r√°pida" # M√°s r√°pido
kp-codeagent --backend groq --model openai/gpt-oss-120b --lang es run "tarea compleja" # M√°s potente

# Usar backend Ollama (local, privado)
kp-codeagent --backend ollama --model codellama:13b --lang es run "tu tarea"

# Auto-detectar mejor backend disponible (prueba Groq ‚Üí OpenAI ‚Üí Ollama)
kp-codeagent --backend auto --lang es run "tu tarea"

# Ajustar creatividad (0.0 = enfocado, 1.0 = creativo)
kp-codeagent --backend groq --lang es --temperature 0.3 run "tu tarea"

# Habilitar modo verboso para depuraci√≥n
kp-codeagent --backend groq --lang es --verbose run "tu tarea"

# Modificar un archivo espec√≠fico
kp-codeagent --backend groq --lang es modify ruta/al/archivo.py "agrega validaci√≥n de entrada"
```

### Comandos Disponibles

```bash
kp-codeagent --help                    # Mostrar ayuda
kp-codeagent check                     # Verificar configuraci√≥n
kp-codeagent setup                     # Descargar/configurar modelos
kp-codeagent modify ARCHIVO TAREA      # Modificar archivo espec√≠fico
```

## üéì C√≥mo Funciona

1. **Analizar**: Escanea tu proyecto para entender el contexto
2. **Planear**: Crea un plan de implementaci√≥n paso a paso
3. **Implementar**: Genera c√≥digo limpio y bien documentado
4. **Verificar**: Te muestra los cambios con resaltado de sintaxis
5. **Confirmar**: Pide tu aprobaci√≥n antes de hacer cambios
6. **Ejecutar**: Aplica cambios con respaldos autom√°ticos

## üîí Caracter√≠sticas de Seguridad

- ‚úÖ **Respaldos Autom√°ticos** - Archivos respaldados antes de modificaci√≥n
- ‚úÖ **Solicitudes de Confirmaci√≥n** - Apruebas todos los cambios
- ‚úÖ **Previsualizar Cambios** - Ver diferencias antes de aplicar
- ‚úÖ **Restaurar desde Respaldo** - Reversi√≥n f√°cil si es necesario
- ‚úÖ **Verificaci√≥n de Permisos** - Valida acceso de escritura
- ‚úÖ **Sin Llamadas Remotas** - Todo se ejecuta localmente

## üéØ Mejores Pr√°cticas

### Escribir Buenas Descripciones de Tareas

**Bueno** ‚úÖ:
- "Crea una funci√≥n para validar n√∫meros de tarjeta de cr√©dito usando el algoritmo de Luhn"
- "Agrega limitaci√≥n de tasa a los endpoints de API en server.py"
- "Corrige la fuga de memoria en el pipeline de procesamiento de im√°genes"

**Muy Vago** ‚ùå:
- "Hazlo mejor"
- "Corrige errores"
- "Actualiza el c√≥digo"

### Consejos para Mejores Resultados

1. **S√© Espec√≠fico**: Describe claramente lo que quieres
2. **Proporciona Contexto**: Menciona nombres de archivos o funciones cuando sea relevante
3. **Una Tarea a la Vez**: Divide tareas complejas en pasos m√°s peque√±os
4. **Revisa los Cambios**: Siempre revisa el c√≥digo antes de aceptar
5. **Aprende de las Explicaciones**: KP Code Agent explica sus decisiones

## üõ†Ô∏è Configuraci√≥n

### Backends Disponibles

#### Groq (Recomendado para WSL)
```bash
kp-codeagent --backend groq --lang es run "tu tarea"
```

**Modelos Groq**:
- `llama-3.3-70b-versatile` - Mejor para c√≥digo (predeterminado)
- `llama-3.1-8b-instant` - M√°s r√°pido
- `openai/gpt-oss-120b` - M√°xima calidad

**Ventajas**: 20x m√°s r√°pido, 0 RAM, gratis

#### Ollama (Local y Privado)
```bash
kp-codeagent --backend ollama --model codellama:7b --lang es run "tu tarea"
```

**Modelos Ollama**:
- `codellama:7b` - M√°s r√°pido, usa menos RAM
- `codellama:13b` - M√°s capaz, requiere 16GB RAM
- `codellama:34b` - M√°s capaz, requiere 32GB RAM

**Ventajas**: 100% privado, sin internet

### Ajustar Temperatura

La temperatura controla la creatividad (0.0 - 1.0):
- `0.0-0.3`: Enfocado, determinista (bueno para correcci√≥n de errores)
- `0.4-0.7`: Balanceado (predeterminado: 0.7)
- `0.8-1.0`: Creativo (bueno para lluvia de ideas)

```bash
kp-codeagent --lang es --temperature 0.3 "corrige error de sintaxis en main.py"
```

## üêõ Soluci√≥n de Problemas

### Groq es muy lento o da timeout

**S√≠ntoma**: Groq tarda m√°s de 5 segundos

**Soluci√≥n**:
```bash
# 1. Verifica tu conexi√≥n a internet
ping api.groq.com

# 2. Verifica que la API key sea correcta
echo $GROQ_API_KEY

# 3. Prueba con modelo m√°s r√°pido
kp-codeagent --backend groq --model llama-3.1-8b-instant --lang es run "tarea"
```

### Error: "API key not found"

```bash
# Verifica que la key est√© exportada
echo $GROQ_API_KEY

# Si no muestra nada, exp√≥rtala
export GROQ_API_KEY="gsk_tu_key_aqui"

# Para que sea permanente, agr√©gala a .bashrc
echo 'export GROQ_API_KEY="gsk_tu_key"' >> ~/.bashrc
source ~/.bashrc
```

### Ollama No Est√° Ejecut√°ndose

```bash
# Verifica el estado de Ollama
curl http://localhost:11434/api/tags

# Inicia Ollama (Linux/macOS)
ollama serve

# Inicia Ollama (Windows)
# Ejecuta Ollama desde el Men√∫ Inicio
```

### Modelo de Ollama No Encontrado

```bash
# Descarga el modelo
ollama pull codellama:7b

# Verifica que est√© disponible
ollama list
```

### Ollama muy lento en WSL

**Soluci√≥n**: Usa Groq en su lugar (20x m√°s r√°pido)
```bash
pip install groq
export GROQ_API_KEY="gsk_tu_key_aqui"
kp-codeagent --backend groq --lang es run "tu tarea"
```

## üìÑ Licencia

Licencia MIT - ver archivo LICENSE para detalles

## üí¨ Soporte

- **Documentaci√≥n**: Consulta este README y ayuda en l√≠nea
- **Issues**: https://github.com/kp-codeagent/kp-codeagent/issues
- **Discusiones**: https://github.com/kp-codeagent/kp-codeagent/discussions

## üó∫Ô∏è Hoja de Ruta

- [ ] Conversaciones de m√∫ltiples turnos
- [ ] Generaci√≥n autom√°tica de pruebas
- [ ] Modo de revisi√≥n de c√≥digo
- [ ] Integraci√≥n con Git
- [ ] Plantillas de proyecto
- [ ] Extensi√≥n de VS Code
- [ ] Interfaz web UI
- [ ] Soporte para m√°s modelos (GPT4All, etc.)

---

**Hecho con ‚ù§Ô∏è para estudiantes aprendiendo a programar**

*KP Code Agent - Tu compa√±ero de c√≥digo local con IA*
